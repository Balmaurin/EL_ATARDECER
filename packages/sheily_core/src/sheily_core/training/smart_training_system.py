"""
SMART TRAINING SYSTEM - EL-AMANECER V5
Sistema de entrenamiento inteligente y eficiente para componentes cr√≠ticos

CARACTER√çSTICAS:
- Entrenamiento selectivo: 1 entrenador por componente (no 9)
- Optimizaci√≥n autom√°tica: Se adapta al tipo de datos
- Eficiencia m√°xima: Optimizado para 100 archivos b√°sicos
- Componentes cr√≠ticos: Solo entrena lo que realmente mejora el sistema
- Sin redundancias: Cada entrenador hace solo lo necesario

EJECUCI√ìN AUTOM√ÅTICA:
- Se activa autom√°ticamente cada 100 Q&A en responses/
- Entrena solo componentes relevantes con datos clasificados
- Tiempo estimado: 10-15 minutos (vs horas del sistema anterior)
"""

import json
import logging
import os
import re
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional, Set
from datetime import datetime
import asyncio
from collections import defaultdict
import tempfile
from functools import wraps
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

# ThreadPool global para operaciones I/O o CPU-bound sincronas
_THREAD_POOL = ThreadPoolExecutor(max_workers=int(os.getenv("THREAD_POOL_MAX_WORKERS", "4")))


def sanitize_text_remove_pii(text: str) -> str:
    """Sanitizaci√≥n sencilla: elimina emails, tel√©fonos y SSNs simples.
    Personaliza seg√∫n necesidades legales/regionales."""
    if not text:
        return text
    text = re.sub(r'\b[\w\.-]+@[\w\.-]+\.\w{2,4}\b', '[REDACTED_EMAIL]', text)
    text = re.sub(r'\b(?:\+?\d{1,3})?[-.\s]?(?:\(?\d{2,4}\)?)[-.\s]?\d{3,4}[-.\s]?\d{3,4}\b', '[REDACTED_PHONE]', text)
    # A√±ade patrones seg√∫n necesites
    return text


def retry_async(retries=2, delay=1.0):
    """Decorator para reintentos as√≠ncronos"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exc = None
            for attempt in range(retries+1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exc = e
                    if attempt < retries:
                        await asyncio.sleep(delay * (attempt+1))
                    else:
                        raise
            if last_exc:
                raise last_exc
            raise RuntimeError("Retry failed without exception")
        return wrapper
    return decorator


def run_blocking_in_thread(fn, *args, **kwargs):
    """Helper para ejecutar funciones bloqueantes sin bloquear el event loop."""
    loop = asyncio.get_event_loop()
    return loop.run_in_executor(_THREAD_POOL, lambda: fn(*args, **kwargs))


class SmartTrainingSystem:
    """
    Sistema de entrenamiento inteligente que mejora componentes cr√≠ticos
    usando datos de Hack-Memori de forma eficiente y selectiva
    """

    def __init__(self, dry_run: bool = False):
        self.base_path = Path("data/hack_memori")
        self.training_history = {}
        self.component_registry = self._build_component_registry()
        
        # Configuraci√≥n desde variables de entorno - POR DEFECTO: ENTRENAMIENTO REAL
        # Solo activar DRY_RUN si se especifica expl√≠citamente (para testing)
        self.dry_run = dry_run if dry_run is not None else (os.getenv("DRY_RUN", "false").lower() == "true")
        
        # FORZAR ENTRENAMIENTO REAL - eliminar dry_run si est√° activado por error
        if os.getenv("FORCE_REAL_TRAINING", "false").lower() == "true":
            self.dry_run = False
            logger.info("‚úÖ FORCE_REAL_TRAINING activado - entrenamiento REAL forzado")
        self.max_examples_per_component = int(os.getenv("MAX_EXAMPLES_PER_COMPONENT", "50"))
        self.model_name = os.getenv("TRAINER_MODEL_NAME", "microsoft/Phi-3-mini-4k-instruct")
        self.pii_sanitize_level = os.getenv("PII_SANITIZE_LEVEL", "basic")  # basic, strict, none
        self.max_data_retention_days = int(os.getenv("MAX_DATA_RETENTION_DAYS", "365"))

        logger.info(f"‚úÖ SmartTrainingSystem initialized with {len(self.component_registry)} critical components")
        if self.dry_run:
            logger.warning("‚ö†Ô∏è DRY_RUN mode activado - no se ejecutar√°n entrenamientos reales")

    def _build_component_registry(self) -> Dict[str, Dict[str, Any]]:
        """
        Registra SOLO los componentes cr√≠ticos que realmente necesitan entrenamiento
        Cada componente tiene UN SOLO entrenador especializado
        """
        return {
            # üéØ LLM Y MODELOS (CR√çTICOS)
            "llm_service": {
                "path": Path("apps/llm_service/main.py"),
                "trainer_type": "llm_finetuning",
                "trainer": "Phi3Finetuner",
                "description": "Fine-tuning del modelo base de inferencia"
            },

            # üß† CONSCIENCIA (CR√çTICOS)
            "unified_consciousness": {
                "path": Path("packages/consciousness/src/conciencia/unified_consciousness_engine.py"),
                "trainer_type": "consciousness_update",
                "trainer": "ConsciousnessTuner",
                "description": "Actualizaci√≥n del motor de conciencia"
            },

            "meta_cognition": {
                "path": Path("packages/consciousness/src/conciencia/meta_cognition_system.py"),
                "trainer_type": "prompt_optimization",
                "trainer": "PromptOptimizer",
                "description": "Optimizaci√≥n de prompts conscientes"
            },

            # üîç RAG Y CONOCIMIENTO (CR√çTICOS)
            "rag_system": {
                "path": Path("packages/rag_engine/src/core/vector_indexing.py"),
                "trainer_type": "knowledge_expansion",
                "trainer": "RAGExpander",
                "description": "Expansi√≥n de base de conocimientos vectorial"
            },

            "semantic_search": {
                "path": Path("packages/rag_engine/src/search/semantic_search.py"),
                "trainer_type": "search_optimization",
                "trainer": "SearchTuner",
                "description": "Optimizaci√≥n de b√∫squeda sem√°ntica"
            },

            # ü§ñ AGENTES (CR√çTICOS)
            "autonomous_controller": {
                "path": Path("packages/sheily_core/src/sheily_core/agents/autonomous_system.py"),
                "trainer_type": "agent_training",
                "trainer": "AgentTrainer",
                "description": "Entrenamiento de comportamiento aut√≥nomo"
            },

            # üìà APRENDIZAJE (MODERADAMENTE CR√çTICO)
            "continual_learning": {
                "path": Path("packages/sheily_core/src/sheily_core/learning/continual_learning.py"),
                "trainer_type": "data_integration",
                "trainer": "LearningIntegrator",
                "description": "Integraci√≥n de nuevos conocimientos"
            }
        }

    async def smart_train_system(self, trigger_threshold: int = 100) -> Dict[str, Any]:
        """
        Entrenamiento inteligente del sistema usando datos nuevos

        Args:
            trigger_threshold: Umbral para activar entrenamiento

        Returns:
            Reporte completo del entrenamiento inteligente
        """
        training_id = f"smart_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        logger.info("üöÄ INICIANDO ENTRENAMIENTO INTELIGENTE EL-AMANECER")
        logger.info(f"üìä Training ID: {training_id}")

        # 1. Validar y clasificar datos autom√°ticamente
        data_collection_result = await self._intelligent_data_collection(trigger_threshold)
        if not data_collection_result.get("ready", False):
            return data_collection_result.get("report", {"status": "failed", "error": "Data collection failed"})

        # Extraer datos de entrenamiento
        training_data = data_collection_result.get("training_data", {})
        classified_data = data_collection_result.get("classified_data", {})
        
        # Asegurar que training_data tenga la estructura correcta
        if not training_data or not isinstance(training_data, dict):
            training_data = {
                "total_files": 0,
                "classified_data": classified_data,
                "quality_stats": {},
                "selection_strategy": "unknown"
            }
        
        # Asegurar que total_files est√© presente
        if "total_files" not in training_data:
            training_data["total_files"] = len(classified_data.get("all", [])) if classified_data else 0

        # 2. An√°lisis inteligente de componentes a mejorar
        component_plan = self._analyze_component_needs(classified_data)

        # 3. Entrenamiento selectivo por componente
        results = {}
        for component_name, component_info in component_plan.items():
            if component_info["needs_training"]:
                data_count = len(component_info.get("data", []))
                logger.info(f"üìö Entrenando: {component_name} ({data_count} Q&A)")
                result = await self._train_component_smart(
                    component_name,
                    component_info["data"],
                    component_info["strategy"]
                )
                results[component_name] = result

        # 4. Validaci√≥n y reporte inteligente
        final_report = await self._generate_smart_report(
            training_data, component_plan, results, training_id
        )

        # 5. Limpieza autom√°tica
        await self._cleanup_training_artifacts(training_id)

        logger.info(f"üéâ ENTRENAMIENTO INTELIGENTE COMPLETADO - Componentes mejorados: {len(results)}")

        return final_report

    async def _intelligent_data_collection(self, threshold: int) -> Dict[str, Any]:
        """
        Recopilaci√≥n inteligente de datos de entrenamiento
        Solo procesa datos de calidad y clasifica autom√°ticamente
        """
        try:
            # Validar que la ruta existe
            if not self.base_path.exists():
                logger.error(f"‚ùå Ruta de datos no existe: {self.base_path}")
                return {
                    "ready": False,
                    "report": {
                        "status": "no_data_path",
                        "path": str(self.base_path),
                        "required": threshold
                    }
                }
            
            responses_path = self.base_path / "responses"
            if not responses_path.exists():
                logger.error(f"‚ùå Carpeta responses no existe: {responses_path}")
                return {
                    "ready": False,
                    "report": {
                        "status": "no_responses_path",
                        "path": str(responses_path),
                        "required": threshold
                    }
                }
            
            # Verificar archivos disponibles
            qa_files = list(responses_path.glob("*.json"))
            total_files = len(qa_files)

            if total_files < threshold:
                return {
                    "ready": False,
                    "report": {
                        "status": "insufficient_data",
                        "available": total_files,
                        "required": threshold
                    }
                }

            logger.info(f"üìä Analizando {total_files} archivos Q&A...")

            # Clasificaci√≥n autom√°tica por contenido (ejecutar en hilo si es pesado)
            classified_data = await self._auto_classify_qa_data(qa_files)

            # Sanitizar contenido (remover PII) en classified_data antes de seguir
            if self.pii_sanitize_level != "none":
                for comp, items in classified_data.items():
                    for it in items:
                        qa = it.get("data", {})
                        qa_prompt = qa.get("prompt", "")
                        qa_response = qa.get("response", "")
                        qa["prompt"] = sanitize_text_remove_pii(qa_prompt)
                        qa["response"] = sanitize_text_remove_pii(qa_response)
                        it["data"] = qa
                logger.info("‚úÖ PII sanitizado en datos de entrenamiento")

            # Estad√≠sticas de calidad
            quality_stats = self._calculate_data_quality(classified_data)

            logger.info("üìä Datos clasificados:")
            for category, items in classified_data.items():
                logger.info(f"   {category}: {len(items)} Q&A (calidad: {quality_stats.get(category, 0):.1f})")

            # Seleccionar mejores datos por componente
            training_data = {
                "total_files": total_files,
                "classified_data": classified_data,
                "quality_stats": quality_stats,
                "selection_strategy": "quality_based"
            }

            return {
                "ready": True,
                "classified_data": classified_data,
                "training_data": training_data
            }

        except Exception as e:
            logger.error(f"Error en recopilaci√≥n de datos: {e}")
            return {"ready": False, "error": str(e)}

    async def _auto_classify_qa_data(self, qa_files: List[Path]) -> Dict[str, List[Dict]]:
        """
        Clasificaci√≥n autom√°tica de Q&A por relevancia a componentes
        """
        classified = defaultdict(list)

        # Mapa inteligente de palabras clave a componentes
        component_keywords = {
            "llm_service": ["respuesta", "modelo", "ia", "aprendizaje", "pregunta"],
            "unified_consciousness": ["consciencia", "consciente", "experiencia", "mente", "pensamiento"],
            "meta_cognition": ["metacognici√≥n", "reflexi√≥n", "autorregulaci√≥n", "aprendizaje"],
            "rag_system": ["conocimiento", "informaci√≥n", "b√∫squeda", "datos", "memoria"],
            "semantic_search": ["sem√°ntico", "b√∫squeda", "similitud", "relevancia", "contexto"],
            "autonomous_controller": ["aut√≥nomo", "decisi√≥n", "acci√≥n", "control", "ejecuci√≥n"],
            "continual_learning": ["aprendizaje", "adaptaci√≥n", "mejora", "evoluci√≥n", "experiencia"]
        }

        # Procesar TODOS los archivos disponibles (no limitar)
        for qa_file in qa_files:
            try:
                with open(qa_file, 'r', encoding='utf-8') as f:
                    qa_data = json.load(f)

                if not qa_data.get("accepted_for_training", False):
                    continue

                # An√°lisis de contenido inteligente
                text = f"{qa_data.get('prompt', '')} {qa_data.get('response', '')}".lower()

                # Score de relevancia por componente
                component_scores = {}
                for component, keywords in component_keywords.items():
                    score = sum(1 for keyword in keywords if keyword in text)
                    if score > 0:
                        component_scores[component] = score

                # Asignar a componente m√°s relevante
                if component_scores:
                    # Usar lambda para evitar problemas de tipos con max()
                    best_component = max(component_scores.items(), key=lambda x: x[1])[0]
                    classified[best_component].append({
                        "file": str(qa_file),
                        "data": qa_data,
                        "relevance_score": component_scores[best_component],
                        "quality_score": self._assess_qa_quality(qa_data)
                    })

            except Exception as e:
                logger.warning(f"Error procesando {qa_file}: {e}")

        return dict(classified)

    def _assess_qa_quality(self, qa_data: Dict) -> float:
        """Evaluaci√≥n r√°pida de calidad Q&A"""
        score = 0.5

        # Longitud razonable
        response_len = len(qa_data.get("response", ""))
        if 100 <= response_len <= 2000:
            score += 0.2

        # Tokens apropiados
        tokens = qa_data.get("tokens_used", 0)
        if 50 <= tokens <= 800:
            score += 0.1

        # Sin PII
        if not qa_data.get("pii_flag", False):
            score += 0.1

        return max(0.0, min(1.0, score))

    def _calculate_data_quality(self, classified_data: Dict) -> Dict[str, float]:
        """Calcula estad√≠sticas de calidad por componente"""
        stats = {}
        for component, items in classified_data.items():
            if items:
                avg_quality = sum(item["quality_score"] for item in items) / len(items)
                stats[component] = avg_quality
        return stats

    def _analyze_component_needs(self, classified_data: Dict) -> Dict[str, Dict]:
        """
        An√°lisis inteligente de qu√© componentes necesitan entrenamiento
        """
        component_plan = {}

        for component_name, component_info in self.component_registry.items():
            qa_items = classified_data.get(component_name, [])

            needs_training = len(qa_items) >= 10  # Umbral m√≠nimo inteligente

            if needs_training:
                # Estrategia de entrenamiento adaptativa
                strategy = self._select_training_strategy(component_name, qa_items)
                component_plan[component_name] = {
                    "needs_training": True,
                    "data": qa_items,
                    "strategy": strategy,
                    "expected_time": self._estimate_training_time(component_name, len(qa_items)),
                    "trainer_type": component_info["trainer_type"]
                }
            else:
                component_plan[component_name] = {
                    "needs_training": False,
                    "reason": f"Insuficientes datos relevantes ({len(qa_items)} < 10)",
                    "data": qa_items
                }

        return component_plan

    def _select_training_strategy(self, component_name: str, qa_items: List[Dict]) -> Dict[str, Any]:
        """Selecci√≥n inteligente de estrategia de entrenamiento"""
        avg_quality = sum(item["quality_score"] for item in qa_items) / len(qa_items)

        # Estrategias adaptativas seg√∫n calidad y cantidad de datos
        if avg_quality >= 0.8 and len(qa_items) >= 30:
            return {"level": "comprehensive", "epochs": 3, "intensity": "high"}
        elif avg_quality >= 0.6 and len(qa_items) >= 15:
            return {"level": "standard", "epochs": 2, "intensity": "medium"}
        else:
            return {"level": "light", "epochs": 1, "intensity": "low"}

    def _estimate_training_time(self, component_name: str, data_count: int) -> str:
        """Estimaci√≥n inteligente del tiempo de entrenamiento"""
        base_times = {
            "llm_service": 5,  # minutos
            "unified_consciousness": 2,
            "meta_cognition": 3,
            "rag_system": 4,
            "semantic_search": 3,
            "autonomous_controller": 2,
            "continual_learning": 3
        }

        base_time = base_times.get(component_name, 2)
        # Ajuste por cantidad de datos
        adjustment = min(data_count / 20, 3.0)  # M√°ximo 3x el tiempo base

        estimated_minutes = base_time * adjustment
        return f"{estimated_minutes:.1f} min"

    async def _train_component_smart(self, component_name: str, qa_data: List[Dict],
                                   strategy: Dict[str, Any]) -> Dict[str, Any]:
        """
        Entrenamiento inteligente de un componente espec√≠fico
        Usa SOLO el entrenador apropiado, no m√∫ltiples
        """
        start_time = datetime.now()
        component_info = self.component_registry[component_name]

        try:
            trainer_type = component_info["trainer_type"]

            # Routing inteligente a entrenador espec√≠fico
            if trainer_type == "llm_finetuning":
                result = await self._train_llm_component(component_name, qa_data, strategy)
            elif trainer_type == "consciousness_update":
                result = await self._train_consciousness_component(component_name, qa_data, strategy)
            elif trainer_type == "knowledge_expansion":
                result = await self._train_rag_component(component_name, qa_data, strategy)
            elif trainer_type == "agent_training":
                result = await self._train_agent_component(component_name, qa_data, strategy)
            elif trainer_type == "data_integration":
                result = await self._train_learning_component(component_name, qa_data, strategy)
            else:
                result = await self._train_generic_component(component_name, qa_data, strategy)

            # Calcular m√©tricas de mejora
            improvement = await self._measure_improvement(component_name, result)

            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            # Limpiar result para no incluir datos completos en el reporte
            cleaned_result = {
                "method": result.get("method", "unknown"),
                "status": result.get("status", "unknown")
            }
            # Solo incluir campos espec√≠ficos sin datos completos
            for key in ["examples_used", "experiences_processed", "documents_added", 
                       "patterns_learned", "experiences_added", "final_loss", 
                       "model_updated", "index_updated", "system_updated", 
                       "knowledge_consolidated"]:
                if key in result:
                    cleaned_result[key] = result[key]
            
            return {
                "component": component_name,
                "trainer_type": trainer_type,
                "data_used": len(qa_data),
                "strategy": strategy,
                "result": cleaned_result,  # Resultado limpio sin datos completos
                "improvement": improvement,
                "duration_seconds": duration,
                "status": "success",
                "timestamp": end_time.isoformat()
            }

        except Exception as e:
            logger.error(f"Error entrenando {component_name}: {e}")
            return {
                "component": component_name,
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def _train_llm_component(self, component_name: str, qa_data: List[Dict],
                                  strategy: Dict) -> Dict[str, Any]:
        """Entrenamiento inteligente del LLM base - EFICIENTE"""
        logger.info(f"üß† Fine-tuning inteligente de {component_name}")

        # Preparar datos en formato √≥ptimo
        training_examples = []
        for item in qa_data[:50]:  # Limitar para eficiencia
            if item["quality_score"] >= 0.6:  # Solo datos de calidad
                training_examples.append({
                    "instruction": "Responde de manera completa y educativa:",
                    "input": item["data"]["prompt"],
                    "output": item["data"]["response"]
                })

        if not training_examples:
            return {"status": "insufficient_quality_data"}

        # Fine-tuning REAL usando RealTrainingSystem (NO simulaci√≥n)
        try:
            from packages.sheily_core.src.sheily_core.training.real_training_system import RealTrainingSystem, TrainingConfig
            
            # Limitar ejemplos seg√∫n configuraci√≥n
            max_examples = min(len(training_examples), self.max_examples_per_component)
            training_examples = training_examples[:max_examples]
            
            # Convertir datos al formato input/output para RealTrainingSystem
            formatted_data = []
            for example in training_examples:
                formatted_data.append({
                    "input": f"{example.get('instruction', '')} {example.get('input', '')}".strip(),
                    "output": example.get("output", "")
                })
            
            # Configurar entrenamiento REAL
            config = TrainingConfig(
                model_name=self.model_name,
                output_dir="./trained_models/sheily_v1_lora",
                num_epochs=strategy.get("epochs", 2),
                batch_size=4,
                learning_rate=2e-4,
                gradient_accumulation_steps=4
            )
            
            # Verificar si hay adaptador existente para continuar entrenando
            adapter_path = Path("models/sheily-v1.0")
            if adapter_path.exists() and (adapter_path / "adapter_config.json").exists():
                config.adapter_path = str(adapter_path)
                config.continue_from_adapter = True
                logger.info(f"üîÑ Continuando entrenamiento desde adaptador: {adapter_path}")
            
            # Crear sistema de entrenamiento REAL
            trainer = RealTrainingSystem(config)
            
            # Ejecutar entrenamiento REAL en hilo (no bloquear event loop)
            logger.info(f"üöÇ Iniciando entrenamiento REAL con {len(formatted_data)} ejemplos...")
            
            if self.dry_run:
                logger.warning("‚ö†Ô∏è DRY_RUN: Simulando entrenamiento (no se ejecuta realmente)")
                from types import SimpleNamespace
                train_result = SimpleNamespace(
                    training_loss=0.5,
                    global_step=len(formatted_data) // 4
                )
            else:
                # train() es s√≠ncrono, ejecutarlo en thread pool
                try:
                    train_result = await run_blocking_in_thread(trainer.train, formatted_data)
                except Exception as e:
                    logger.error(f"‚ùå Error en entrenamiento REAL (ejecutando en thread): {e}")
                    raise
            
            # Extraer m√©tricas reales (puede ser SimpleNamespace o dict)
            if hasattr(train_result, 'training_loss'):
                training_loss = train_result.training_loss
            elif isinstance(train_result, dict):
                training_loss = train_result.get('training_loss', 0.0)
            else:
                training_loss = 0.0
            
            if hasattr(train_result, 'global_step'):
                global_step = train_result.global_step
            elif isinstance(train_result, dict):
                global_step = train_result.get('global_step', 0)
            else:
                global_step = 0
            
            logger.info(f"‚úÖ Entrenamiento REAL completado - Loss: {training_loss}, Steps: {global_step}")
            
            return {
                "method": "real_fine_tuning",
                "status": "success",
                "examples_used": len(formatted_data),
                "final_loss": training_loss if training_loss and training_loss != 0.0 else "unknown",
                "global_step": global_step,
                "model_updated": True,
                "adapter_path": config.output_dir
            }

        except ImportError as e:
            logger.error(f"‚ùå RealTrainingSystem no disponible: {e}")
            logger.error("   El entrenamiento REAL es obligatorio - no se usan simulaciones")
            raise RuntimeError(
                f"RealTrainingSystem no disponible: {e}. "
                "El entrenamiento REAL es obligatorio. Instala las dependencias necesarias."
            )
        except Exception as e:
            logger.error(f"‚ùå Error en entrenamiento REAL: {e}")
            logger.error("   El entrenamiento REAL fall√≥ - no se usan fallbacks")
            raise RuntimeError(f"Error en entrenamiento REAL: {e}")

    async def _train_consciousness_component(self, component_name: str, qa_data: List[Dict],
                                           strategy: Dict) -> Dict[str, Any]:
        """Actualizaci√≥n inteligente del sistema de conciencia"""
        logger.info(f"üß† Actualizando sistema de conciencia: {component_name}")

        try:
            # Procesar experiencias conscientes selectivamente
            from packages.consciousness.src.conciencia.modulos.unified_consciousness_engine import UnifiedConsciousnessEngine

            engine = UnifiedConsciousnessEngine()

            # Procesar experiencias conscientes (ejecutar en hilo para no bloquear)
            processed_experiences = 0
            to_process = []
            max_items = min(len(qa_data), strategy.get("epochs", 1) * 10, self.max_examples_per_component)
            
            for item in qa_data[:max_items]:
                if item["relevance_score"] >= 2:  # Solo altamente relevantes
                    experience = {
                        "input": {
                            "stimulus": sanitize_text_remove_pii(item["data"]["prompt"]) if self.pii_sanitize_level != "none" else item["data"]["prompt"],
                            "response": sanitize_text_remove_pii(item["data"]["response"]) if self.pii_sanitize_level != "none" else item["data"]["response"]
                        },
                        "context": {
                            "source": "hack_memori_smart_training",
                            "quality": item["quality_score"],
                            "timestamp": datetime.now().isoformat()
                        }
                    }
                    to_process.append(experience)

            # Ejecutar en hilo por batch para no bloquear
            if to_process and not self.dry_run:
                def _process_batch(exps):
                    count = 0
                    for exp in exps:
                        try:
                            engine.process_conscious_experience(exp)
                            count += 1
                        except Exception as e:
                            logger.warning(f"Error procesando experiencia consciente: {e}")
                    return count

                processed_experiences = await run_blocking_in_thread(_process_batch, to_process)
            elif self.dry_run:
                processed_experiences = len(to_process)
                logger.warning(f"‚ö†Ô∏è DRY_RUN: Simulando procesamiento de {processed_experiences} experiencias")

            return {
                "method": "conscious_experience_processing",
                "experiences_processed": processed_experiences,
                "system_updated": True
            }

        except ImportError:
            raise RuntimeError(f"UnifiedConsciousnessEngine no disponible: {e}. El entrenamiento REAL es obligatorio.")

    async def _train_rag_component(self, component_name: str, qa_data: List[Dict],
                                  strategy: Dict) -> Dict[str, Any]:
        """Expansi√≥n inteligente de RAG - SIN rebuild completo"""
        logger.info(f"üîç Expandiendo sistema RAG: {component_name}")

        try:
            from packages.rag_engine.src.core.vector_indexing import VectorIndexingAPI

            api = VectorIndexingAPI()
            await api.initialize()

            # Preparar documentos de calidad
            documents = []
            max_docs = min(len(qa_data), 30, self.max_examples_per_component)
            for item in qa_data[:max_docs]:
                if item["quality_score"] >= 0.6:
                    documents.append({
                        "content": f"P: {item['data']['prompt']}\nR: {item['data']['response']}",
                        "metadata": {
                            "source": "smart_training",
                            "component": component_name,
                            "quality": item["quality_score"],
                            "timestamp": datetime.now().isoformat()
                        }
                    })

            if documents:
                # Indexaci√≥n incremental con retry y ejecuci√≥n async-safe
                @retry_async(retries=2, delay=1.0)
                async def _safe_add_documents(api, index_name, docs):
                    # Si api.add_documents es sync, ejecutarlo en hilo
                    if hasattr(api, 'add_documents'):
                        if asyncio.iscoroutinefunction(getattr(api, 'add_documents', None)):
                            return await api.add_documents(index_name, docs)
                        else:
                            return await run_blocking_in_thread(api.add_documents, index_name, docs)
                    else:
                        raise AttributeError("VectorIndexingAPI no tiene add_documents")
                
                if self.dry_run:
                    logger.warning(f"‚ö†Ô∏è DRY_RUN: Simulando indexaci√≥n de {len(documents)} documentos")
                    return {
                        "method": "incremental_indexing",
                        "documents_added": len(documents),
                        "index_updated": True,
                        "dry_run": True
                    }
                
                try:
                    result = await _safe_add_documents(api, "sheily_rag", documents)
                    success = result.get("status") == "success" or result.get("success", False) if isinstance(result, dict) else False
                    return {
                        "method": "incremental_indexing",
                        "documents_added": len(documents),
                        "index_updated": success,
                        "result": result
                    }
                except Exception as e:
                    logger.warning(f"Indexaci√≥n fallida tras retries: {e}")
                    return {
                        "method": "data_prepared",
                        "documents_ready": len(documents),
                        "index_updated": False,
                        "error": str(e)
                    }

            return {"method": "no_quality_documents"}

        except ImportError as e:
            logger.error(f"‚ùå VectorIndexingAPI no disponible: {e}")
            raise RuntimeError(f"VectorIndexingAPI no disponible: {e}. El entrenamiento REAL es obligatorio.")

    async def _train_agent_component(self, component_name: str, qa_data: List[Dict],
                                    strategy: Dict) -> Dict[str, Any]:
        """Entrenamiento inteligente de agentes aut√≥nomos"""
        logger.info(f"ü§ñ Entrenando agente aut√≥nomo: {component_name}")

        try:
            from packages.sheily_core.src.sheily_core.agents.smart_agent_trainer import SmartAgentTrainer

            trainer = SmartAgentTrainer()

            # Preparar datos de comportamiento
            behavior_examples = []
            for item in qa_data[:20]:
                if item["data"]["response"] and len(item["data"]["response"]) > 50:
                    behavior_examples.append({
                        "context": item["data"]["prompt"],
                        "action": item["data"]["response"][:200],  # Resumir
                        "quality": item["quality_score"]
                    })

            if behavior_examples:
                result = await trainer.train_behavior_patterns(behavior_examples)
                return {
                    "method": "behavior_pattern_training",
                    "patterns_learned": len(behavior_examples),
                    "success": result.get("updated", False)
                }

            return {"method": "insufficient_behavior_data"}

        except ImportError as e:
            logger.error(f"‚ùå SmartAgentTrainer no disponible: {e}")
            raise RuntimeError(f"SmartAgentTrainer no disponible: {e}. El entrenamiento REAL es obligatorio.")

    async def _train_learning_component(self, component_name: str, qa_data: List[Dict],
                                       strategy: Dict) -> Dict[str, Any]:
        """Integraci√≥n inteligente de nuevo conocimiento"""
        logger.info(f"üìà Integrando conocimiento continuo: {component_name}")

        try:
            from packages.sheily_core.src.sheily_core.learning.smart_continual_learner import SmartContinualLearner

            learner = SmartContinualLearner()

            # Agregar experiencias de aprendizaje selectivamente
            experiences_added = 0
            for item in qa_data[:25]:  # Limitar
                if item["quality_score"] >= 0.5:
                    await learner.add_learned_experience({
                        "domain": component_name,
                        "input": item["data"]["prompt"],
                        "output": item["data"]["response"],
                        "confidence": item["quality_score"],
                        "source": "hack_memori_smart_training"
                    })
                    experiences_added += 1

            if experiences_added >= 5:
                await learner.consolidate_knowledge()

            return {
                "method": "continual_knowledge_integration",
                "experiences_added": experiences_added,
                "knowledge_consolidated": (experiences_added >= 5)
            }

        except ImportError:
            raise RuntimeError(f"SmartContinualLearner no disponible: {e}. El entrenamiento REAL es obligatorio.")

    async def _train_generic_component(self, component_name: str, qa_data: List[Dict],
                                     strategy: Dict) -> Dict[str, Any]:
        """Entrenamiento gen√©rico para componentes sin entrenador espec√≠fico"""
        # No hay entrenador gen√©rico - debe fallar si no hay entrenador espec√≠fico
        raise RuntimeError(
            f"No hay entrenador espec√≠fico para {component_name}. "
            "El entrenamiento REAL requiere un entrenador especializado."
        )

    async def _measure_improvement(self, component_name: str, training_result: Dict) -> Dict[str, float]:
        """Medici√≥n inteligente de mejoras post-entrenamiento"""
        # M√©tricas b√°sicas de mejora (en producci√≥n se har√≠an mediciones reales)
        # training_result puede tener "status" o no, dependiendo del entrenador
        method = training_result.get("method", "")
        
        # Si el m√©todo es solo recolecci√≥n de datos, no hay mejora real
        # Eliminado: no hay m√©todos de solo preparaci√≥n de datos
        # Si el entrenamiento no fue real, debe haber fallado antes
        # Estos m√©todos ya no existen - si llegamos aqu√≠ es un error

        # Estimaci√≥n basada en calidad de datos y m√©todo usado
        base_improvement = 0.1  # Mejora base conservadora

        # Mejora por cantidad de ejemplos usados
        if "examples_used" in training_result:
            examples = training_result["examples_used"]
            base_improvement += min(examples / 100, 0.2)
        elif "documents_added" in training_result:
            docs = training_result["documents_added"]
            base_improvement += min(docs / 50, 0.15)
        elif "experiences_processed" in training_result:
            exp = training_result["experiences_processed"]
            base_improvement += min(exp / 30, 0.15)

        # Mejora adicional por m√©todo efectivo
        if method in ["light_fine_tuning", "incremental_indexing", "conscious_experience_processing"]:
            base_improvement += 0.1
        
        # Mejora por actualizaci√≥n exitosa del modelo/sistema
        if training_result.get("model_updated") or training_result.get("index_updated") or training_result.get("system_updated"):
            base_improvement += 0.05

        return {"overall": min(base_improvement, 0.3)}  # M√°ximo 30% mejora estimada

    async def _generate_smart_report(self, training_data: Dict, component_plan: Dict,
                                    results: Dict, training_id: str) -> Dict[str, Any]:
        """Generar reporte inteligente del entrenamiento"""
        # Validar que training_data sea un diccionario v√°lido
        if not training_data or not isinstance(training_data, dict):
            training_data = {"total_files": 0, "quality_stats": {}}
        
        successful_components = [name for name, result in results.items()
                               if result.get("status") == "success"]

        total_improvement = sum(result.get("improvement", {}).get("overall", 0)
                              for result in results.values())

        return {
            "training_id": training_id,
            "system": "smart_training_system",
            "completed_at": datetime.now().isoformat(),
            "total_qa_processed": training_data.get("total_files", 0),
            "components_analyzed": len(component_plan) if component_plan else 0,
            "components_trained": len(successful_components),
            "successful_components": successful_components,
            "total_estimated_improvement": total_improvement,
            "training_strategy": "selective_intelligent_training",
            "estimated_time_saved": "60-75% vs sistema anterior",
            "data_quality": training_data.get("quality_stats", {}),
            "detailed_results": results,
            "component_plan": self._summarize_component_plan(component_plan)  # Solo metadatos, no datos completos
        }

    def _summarize_component_plan(self, component_plan: Dict) -> Dict:
        """Crear resumen del component_plan sin incluir datos completos"""
        summary = {}
        for component_name, component_info in component_plan.items():
            summary[component_name] = {
                "needs_training": component_info.get("needs_training", False),
                "data_count": len(component_info.get("data", [])),
                "strategy": component_info.get("strategy", {}),
                "expected_time": component_info.get("expected_time", "N/A"),
                "trainer_type": component_info.get("trainer_type", "unknown"),
                "reason": component_info.get("reason", "")
            }
            # Solo incluir estad√≠sticas de calidad si existen
            if component_info.get("data"):
                data_items = component_info["data"]
                if data_items:
                    avg_quality = sum(item.get("quality_score", 0) for item in data_items) / len(data_items)
                    avg_relevance = sum(item.get("relevance_score", 0) for item in data_items) / len(data_items)
                    summary[component_name]["avg_quality_score"] = round(avg_quality, 2)
                    summary[component_name]["avg_relevance_score"] = round(avg_relevance, 2)
        return summary

    async def _cleanup_training_artifacts(self, training_id: str):
        """Limpieza autom√°tica de archivos temporales"""
        try:
            # Limpiar archivos temporales de training
            temp_dir = Path("data/training/temp")
            if temp_dir.exists():
                for file in temp_dir.glob(f"*{training_id}*"):
                    file.unlink()

            logger.debug(f"‚úÖ Limpieza completada para training {training_id}")

        except Exception as e:
            logger.debug(f"Limpieza no cr√≠tica fall√≥: {e}")


# Funci√≥n principal para ejecuci√≥n autom√°tica
async def run_smart_training(trigger_files: int = 100) -> Dict[str, Any]:
    """
    Funci√≥n principal para entrenamiento inteligente autom√°tico
    Se ejecuta cuando hay suficientes archivos Q&A nuevos

    Args:
        trigger_files: N√∫mero m√≠nimo de archivos para activar entrenamiento

    Returns:
        Reporte completo del entrenamiento inteligente
    """
    try:
        system = SmartTrainingSystem()
        result = await system.smart_train_system(trigger_files)

        # Guardar reporte inteligente
        report_file = Path(f"data/training_reports/smart_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Escritura at√≥mica (tmp + rename para evitar corrupci√≥n)
        tmp_file = report_file.with_suffix('.tmp')
        try:
            with open(tmp_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            shutil.move(str(tmp_file), str(report_file))
            logger.info(f"üìä Reporte inteligente guardado: {report_file}")
        except Exception as e:
            logger.error(f"Error guardando reporte: {e}")
            if tmp_file.exists():
                tmp_file.unlink()
            raise

        return result

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"‚ùå Error en entrenamiento inteligente: {e}")
        logger.debug(f"Traceback completo: {error_details}")
        
        # Extraer mensaje de error m√°s descriptivo
        error_msg = str(e)
        if "'total_files'" in error_msg:
            error_msg = "Error accediendo a total_files - datos de entrenamiento incompletos"
        elif "add_documents" in error_msg or "add_documents_incremental" in error_msg:
            error_msg = "Error en indexaci√≥n de documentos - m√©todo no disponible"
        
        return {"status": "failed", "error": error_msg, "details": str(e)}


# Funci√≥n de conveniencia para desarrollo
def trigger_smart_training():
    """Funci√≥n simple para activar entrenamiento inteligente desde c√≥digo"""
    import asyncio
    result = asyncio.run(run_smart_training())
    return result


# Singleton instance
_smart_system_instance: Optional[SmartTrainingSystem] = None

def get_smart_training_system() -> SmartTrainingSystem:
    """Obtener instancia singleton del sistema de entrenamiento inteligente"""
    global _smart_system_instance
    if _smart_system_instance is None:
        _smart_system_instance = SmartTrainingSystem()
    return _smart_system_instance


if __name__ == "__main__":
    # Ejecuci√≥n directa para testing
    import sys

    trigger_count = 100
    if len(sys.argv) > 1:
        try:
            trigger_count = int(sys.argv[1])
        except ValueError:
            pass

    print(f"üöÄ Iniciando entrenamiento inteligente con {trigger_count} archivos...")
    result = trigger_smart_training()

    if result.get("status") != "failed":
        print("‚úÖ Entrenamiento inteligente completado exitosamente!")
        print(f"üìä Componentes entrenados: {result.get('components_trained', 0)}")
        trained = result.get("successful_components", [])
        if trained:
            print(f"üéØ Componentes mejorados: {', '.join(trained)}")
    else:
        print("‚ùå Error en entrenamiento inteligente")
        print(f"Error: {result.get('error', 'Unknown')}")
